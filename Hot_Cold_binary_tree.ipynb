{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "from collections import deque\n",
    "\n",
    "# PARAMETERS\n",
    "DEBUG = True\n",
    "#--------------------------------------------------------------------------------\n",
    "# Structure for the outputs\n",
    "\n",
    "class Status(BaseModel):\n",
    "    status: str = Field(description=\"The status of the chain of thoughts. Either we should continue to reach a final asnwer, we should terminate this chain because it won't reach a final answer and it is going stray. If a we are ready for a final answer (regardless of correctness) return ready\", enum=[\"continue\", \"terminate\", \"ready\"])\n",
    "\n",
    "class Thought(BaseModel):\n",
    "    \"\"\"A thought on how to solve the problem\"\"\"\n",
    "    thought: str = Field(description=\"The thought for the next step\")\n",
    "\n",
    "class Solution(BaseModel):\n",
    "    \"\"\"A solution to solve the problem\"\"\"\n",
    "    solution: str = Field(description=\"The solution to the problem\")\n",
    "\n",
    "class SolutionEvaluation(BaseModel):\n",
    "    \"\"\"Evaluate and compare two solutions\"\"\"\n",
    "    reason: str = Field(description=\"Describe your reasoning for the evaluation\")\n",
    "    choice: str = Field(description=\"The best solution\", enum=[\"solution1\", \"solution2\"])\n",
    "\n",
    "class Equivalence(BaseModel):\n",
    "    \"\"\"Check if two solutions are equivalent\"\"\"\n",
    "    equivalent: bool = Field(description=\"True if the two solutions are equivalent, False otherwise\")\n",
    "\n",
    "# OpenAI models low T, high T, and evaluator\n",
    "class OpenAIParse(object):\n",
    "\n",
    "    def __init__(self, model, response_format, system_prompt):\n",
    "        self.client = OpenAI()\n",
    "        self.model = model\n",
    "        self.response_format= response_format\n",
    "        self.system_prompt = system_prompt\n",
    "\n",
    "    def __call__(self, prompt, temperature = 0):     \n",
    "        completion = self.client.beta.chat.completions.parse(\n",
    "            model=self.model,\n",
    "            temperature=temperature,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            response_format=self.response_format,\n",
    "            #logprobs=True,\n",
    "            #top_logprobs=3,\n",
    "        )\n",
    "        return completion.choices[0].message.parsed\n",
    "#--------------------------------------------------------------------------------\n",
    "Thought_system_prompt = \"\"\"Given the user query and the chain of thoughts, generate the next step (a thought) to solve the problem but do not generate a solution.\n",
    "Do not repeat the same thought twice. Your thought must be a continuation of your previous chain of thoughts. If you are ready to generate a solution, return I am ready.\n",
    "Also remember that you do not have access to any outside tools or sources of knowledge.\"\"\"\n",
    "Thought_user_prompt = \"User query: {query}\\nChain of thoughts: {chain_of_thoughts}\"\n",
    "Thought_model = OpenAIParse(\"gpt-4o-mini\", Thought, Thought_system_prompt)\n",
    "#--------------------------------------------------------------------------------\n",
    "Status_system_prompt = \"\"\"\n",
    "Given the user query and the chain of thoughts, evaluate the chain of thoughts and determine the status of the chain of thoughts.\n",
    "The chain of thoughts is a series of thoughts that are generated to solve a problem.\n",
    "The chain of thoughts can be in one of three states: continue, terminate, ready.\"\"\"\n",
    "Status_user_prompt = \"User query: {query}\\nChain of thoughts: {chain_of_thoughts}\"\n",
    "Status_model = OpenAIParse(\"gpt-4o-mini\", Status, Status_system_prompt)\n",
    "#--------------------------------------------------------------------------------\n",
    "Solution_system_prompt = \"\"\"\n",
    "Given the user query and the chain of thoughts, generate the solution to the problem.\n",
    "The solution is the final answer to the problem.\"\"\"\n",
    "Solution_user_prompt = \"User query: {query}\\nChain of thoughts: {chain_of_thoughts}\"\n",
    "Solution_model = OpenAIParse(\"gpt-4o-mini\", Solution, Solution_system_prompt)\n",
    "#--------------------------------------------------------------------------------\n",
    "Equivalence_system_prompt = \"\"\"\n",
    "Given two solutions and a user query, evaluate if the two solutions are equivalent.\"\"\"\n",
    "Equivalence_user_prompt = \"User query: {query}\\nSolution 1: {solution_1}\\nSolution 2: {solution_2}\"\n",
    "Equivalence_model = OpenAIParse(\"gpt-4o-mini\", Equivalence, Equivalence_system_prompt)\n",
    "#--------------------------------------------------------------------------------\n",
    "Compare_system_prompt = \"\"\"\n",
    "Given the user query, chain of thought and solution 1 and, chain of thought and solution 2, evaluate the solutions and determine the best solution.\"\"\"\n",
    "Compare_user_prompt = \"User query: {query}\\nSolutions 1: {solutions_1}\\nSolutions 2: {solutions_2}\"\n",
    "Compare_model = OpenAIParse(\"gpt-4o-mini\", SolutionEvaluation, Compare_system_prompt)\n",
    "#--------------------------------------------------------------------------------\n",
    "# chain of thoughts\n",
    "\n",
    "class link(object):\n",
    "    \"\"\"A link in a chain of thoughts\"\"\"\n",
    "    def __init__(self, thought, prev = None , status: Status = None):\n",
    "        self.thought = thought\n",
    "        self.thoughts = [thought]\n",
    "        self.status = status\n",
    "        self.next = None\n",
    "        self.prev = None\n",
    "        if prev:\n",
    "            self.prev = prev\n",
    "            self.thoughts = prev.thoughts + [thought]\n",
    "\n",
    "class Chain(object):\n",
    "    \"\"\"A chain of thoughts to solve a problem\"\"\"\n",
    "    def __init__(self, status_model, thought_model, solution_model):\n",
    "        self.head = None\n",
    "        self.tail = None\n",
    "        self.status_model = status_model\n",
    "        self.thought_model = thought_model\n",
    "        self.solution_model = solution_model\n",
    "        self.solution = None\n",
    "\n",
    "    def set_status(self, node, query):\n",
    "        \"\"\"Set the status of the chain of thoughts\"\"\"\n",
    "        node.status = self.status_model(\n",
    "            Status_user_prompt.format(query=query, chain_of_thoughts='\\n-'.join(node.thoughts))\n",
    "            )\n",
    "\n",
    "    def __call__(self, query, T = 0 , max_length: int = 5):\n",
    "        self.head = link(thought = query, status = Status(status=\"continue\"))\n",
    "        node = self.head\n",
    "        for i in range(max_length):\n",
    "            if DEBUG:\n",
    "                print(f\"Current Length: {i} out of {max_length}\")\n",
    "            thought = self.thought_model(\n",
    "                Thought_user_prompt.format(query=query, chain_of_thoughts='\\n-'.join(node.thoughts)), \n",
    "                temperature = T)\n",
    "            node.next = link(thought = thought.thought, prev = node)\n",
    "            node = node.next\n",
    "            self.set_status(node, query)\n",
    "            if node.status.status == \"terminate\" or node.status.status == \"ready\":\n",
    "                break\n",
    "        self.tail = node\n",
    "        self.solution = self.solution_model(\n",
    "            Solution_user_prompt.format(query=query, chain_of_thoughts='\\n-'.join(self.tail.thoughts))\n",
    "            ).solution\n",
    "        return self.solution\n",
    "\n",
    "# tree of thoughts\n",
    "\n",
    "class Node(object):\n",
    "    \"\"\"A node in a tree of thoughts\"\"\"\n",
    "    def __init__(self, thought, parent = None, status: Status = None):\n",
    "        self.thought = thought\n",
    "        self.thoughts = [thought]\n",
    "        self.status = status\n",
    "        self.children = []\n",
    "        self.parent = parent\n",
    "        self.depth = 0\n",
    "        if parent:\n",
    "            self.depth = parent.depth + 1\n",
    "            self.parent = parent\n",
    "            self.thoughts = parent.thoughts + [thought]\n",
    "\n",
    "class BinNode(Node):\n",
    "    \"\"\"A node in a binary tree of thoughts\"\"\"\n",
    "    def __init__(self, thought, parent = None, status: Status = None, low_temp = None, high_temp = None, node_type = \"Hot\"):\n",
    "        super().__init__(thought, parent, status)\n",
    "        self.node_type_chain = [node_type] # list of node types to keep track of the path\n",
    "        self.low_temp = low_temp\n",
    "        self.high_temp = high_temp\n",
    "        if parent:\n",
    "            self.node_type_chain = parent.node_type_chain + [node_type]\n",
    "\n",
    "class Tree(object):\n",
    "    \"\"\"A tree of thoughts to solve a problem\"\"\"\n",
    "    def __init__(self, status_model, thought_model, solution_model,\n",
    "                 equivalence_model = None, best_solution_model = None, max_depth: int = 5, max_children: int = 2):\n",
    "        self.root = None\n",
    "        self.leaves = deque([self.root]) # list of leaves\n",
    "        self.status_model = status_model\n",
    "        self.solution_nodes = []\n",
    "        self.solutions = []\n",
    "        self.solution_thoughts = []\n",
    "        self.max_depth = max_depth\n",
    "        self.max_children = max_children\n",
    "        self.thought_model = thought_model\n",
    "        self.solution_model = solution_model\n",
    "        self.equivalence_model = equivalence_model\n",
    "        self.best_solution_model = best_solution_model\n",
    "\n",
    "    def set_status(self, query):\n",
    "        \"\"\"Set the status of the chain of thoughts\"\"\"\n",
    "        for node in self.leaves:\n",
    "            if not node.status:\n",
    "                node.status = self.status_model(\n",
    "                    Status_user_prompt.format(query=query, chain_of_thoughts='\\n-'.join(node.thoughts))\n",
    "                    )\n",
    "\n",
    "    def prune(self):\n",
    "        \"\"\"Prune the tree by removing nodes that are ready to generate a solution or are terminated due to going stray.\"\"\"\n",
    "        removal = []\n",
    "        for node in self.leaves:\n",
    "            if node.status.status == \"terminate\":\n",
    "                removal.append(node)\n",
    "            elif node.status.status == \"ready\":\n",
    "                self.solution_nodes.append(node)\n",
    "                removal.append(node)\n",
    "        for node in removal:\n",
    "            self.leaves.remove(node)\n",
    "\n",
    "    def check_equivalence(self, query, solution_1, solution_2):\n",
    "        \"\"\"Check if two solutions are equivalent\"\"\"\n",
    "        return self.equivalence_model(\n",
    "            Equivalence_user_prompt.format(query=query, solution_1=solution_1, solution_2=solution_2)).equivalent\n",
    "    \n",
    "    def unique_solutions(self, query):\n",
    "        \"\"\"Remove duplicate solutions\"\"\"\n",
    "        unique_solutions = []\n",
    "        unique_solutions_thoughts = []\n",
    "        for num, solution in enumerate(self.solutions):\n",
    "            if not unique_solutions:\n",
    "                unique_solutions.append(solution)\n",
    "                unique_solutions_thoughts.append(self.solution_thoughts[num])\n",
    "            else:\n",
    "                for unique_solution in unique_solutions:\n",
    "                    if self.check_equivalence(query, solution, unique_solution):\n",
    "                        break\n",
    "                else:\n",
    "                    unique_solutions.append(solution)\n",
    "                    unique_solutions_thoughts.append(self.solution_thoughts[num])\n",
    "        self.solutions = unique_solutions\n",
    "        self.solution_thoughts = unique_solutions_thoughts\n",
    "\n",
    "    def compare_solution(self, query, solutions_1, solutions_2):\n",
    "        \"\"\"Evaluate and compare two solutions\"\"\"\n",
    "        return self.best_solution_model(\n",
    "            Compare_user_prompt.format(query=query, solutions_1=solutions_1, solutions_2=solutions_2)\n",
    "            ).choice\n",
    "    \n",
    "    def best_solution(self, query):\n",
    "        \"\"\"Find the best solution among the unique solutions\"\"\"\n",
    "        if len(self.solutions) == 1:\n",
    "            return (self.solution_thoughts[0], self.solutions[0]) if self.solution_thoughts else ([] , self.solutions[0])\n",
    "        else:\n",
    "            best = self.solutions[0]\n",
    "            best_thoughts = self.solution_thoughts[0]\n",
    "            for i in range(1, len(self.solutions)):\n",
    "                best_thoughts, best = (\n",
    "                    (self.solution_thoughts[i], self.solutions[i]) if self.compare_solution(\n",
    "                        query, best, '\\n-'.join(self.solution_thoughts[i])+\"\\n\"+self.solutions[i]\n",
    "                        ) == \"solution2\" else (best_thoughts, best)\n",
    "                        )\n",
    "            return (best_thoughts, best)\n",
    "\n",
    "    def __call__(self, query, T=0):\n",
    "        self.root = Node(thought = query, status = Status(status=\"continue\"))\n",
    "        node = self.root\n",
    "        self.leaves = deque([self.root])\n",
    "        for depth in range(self.max_depth):\n",
    "            while self.leaves and node.depth < depth:\n",
    "                if DEBUG:\n",
    "                    print(f\"Current Depth: {node.depth} out of {self.max_depth}\")\n",
    "                node = self.leaves.popleft()\n",
    "                for i in range(self.max_children):\n",
    "                    thought = self.thought_model(\n",
    "                        Thought_user_prompt.format(query=query, chain_of_thoughts='\\n-'.join(node.thoughts)), \n",
    "                        temperature = T)\n",
    "                    node.children.append(Node(thought = thought.thought, parent = node))\n",
    "                self.leaves.extend(node.children)\n",
    "            self.set_status(query)\n",
    "            self.prune()\n",
    "        if self.solution_nodes:\n",
    "            self.solutions = [self.solution_model(\n",
    "                Solution_user_prompt.format(query=query, chain_of_thoughts='\\n-'.join(node.thoughts))\n",
    "                ).solution for node in self.solution_nodes]\n",
    "            self.solution_thoughts = [node.thoughts for node in self.solution_nodes]\n",
    "        elif self.leaves:\n",
    "            self.solutions = [self.solution_model(\n",
    "                Solution_user_prompt.format(query=query, chain_of_thoughts='\\n-'.join(node.thoughts))\n",
    "                ).solution for node in self.leaves]\n",
    "            self.solution_thoughts = [node.thoughts for node in self.leaves]\n",
    "        else:\n",
    "            self.solutions = [\"No solution found\"]\n",
    "        if self.equivalence_model:\n",
    "            self.unique_solutions(query)\n",
    "        if self.best_solution_model:\n",
    "            best_thoughts, best = self.best_solution(query)\n",
    "        if not best:\n",
    "            return None, self.solutions\n",
    "        return best_thoughts, best\n",
    "\n",
    "class BinTree(Tree):\n",
    "    \"\"\"A binary tree of thoughts to solve a problem\"\"\"\n",
    "    def __init__(\n",
    "            self, status_model, thought_model, solution_model,\n",
    "            equivalence_model = None, best_solution_model = None,\n",
    "            max_depth: int = 5, low_temp = 0, high_temp = 1.3\n",
    "            ):\n",
    "        super().__init__(\n",
    "            status_model=status_model, thought_model=thought_model,\n",
    "            solution_model=solution_model, equivalence_model=equivalence_model,\n",
    "            best_solution_model=best_solution_model, max_depth=max_depth\n",
    "            )\n",
    "        self.root = None\n",
    "        self.leaves = deque([self.root]) # list of leaves\n",
    "        self.low_temp = low_temp\n",
    "        self.high_temp = high_temp\n",
    "\n",
    "    def __call__(self, query):\n",
    "        self.root = BinNode(thought = query, status = Status(status=\"continue\"))\n",
    "        node = self.root\n",
    "        self.leaves = deque([self.root])\n",
    "        for depth in range(self.max_depth):\n",
    "            while self.leaves and node.depth < self.max_depth:\n",
    "                if DEBUG:\n",
    "                    print(f\"Current Depth: {node.depth} out of {self.max_depth}\")\n",
    "                node = self.leaves.popleft()\n",
    "                thought = self.thought_model(\n",
    "                    Thought_user_prompt.format(query=query, chain_of_thoughts='\\n-'.join(node.thoughts)), \n",
    "                    temperature = self.low_temp)\n",
    "                node.low_temp = BinNode(thought = thought.thought, parent = node, node_type = \"Cold\")\n",
    "                thought = self.thought_model(\n",
    "                    Thought_user_prompt.format(query=query, chain_of_thoughts='\\n-'.join(node.thoughts)), \n",
    "                    temperature = self.high_temp)\n",
    "                node.high_temp = BinNode(thought = thought.thought, parent = node, node_type = \"Hot\")\n",
    "                self.leaves.extend([node.low_temp, node.high_temp])\n",
    "            self.set_status(query)\n",
    "            self.prune()\n",
    "        if self.solution_nodes:\n",
    "            self.solutions = [self.solution_model(\n",
    "                Solution_user_prompt.format(query=query, chain_of_thoughts='\\n-'.join(node.thoughts))\n",
    "                ).solution for node in self.solution_nodes]\n",
    "            self.solution_thoughts = [node.thoughts for node in self.solution_nodes]\n",
    "        elif self.leaves:\n",
    "            self.solutions = [self.solution_model(\n",
    "                Solution_user_prompt.format(query=query, chain_of_thoughts='\\n-'.join(node.thoughts))\n",
    "                ).solution for node in self.leaves]\n",
    "            self.solution_thoughts = [node.thoughts for node in self.leaves]\n",
    "        else:\n",
    "            self.solutions = [\"No solution found\"]        \n",
    "        if self.equivalence_model:\n",
    "            self.unique_solutions(query)\n",
    "        if self.best_solution_model:\n",
    "            best_thoughts, best = self.best_solution(query)\n",
    "        if not best:\n",
    "            return None, self.solutions\n",
    "        return best_thoughts, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Depth: 0 out of 5\n",
      "Current Depth: 0 out of 5\n",
      "Current Depth: 1 out of 5\n",
      "Current Depth: 1 out of 5\n",
      "Current Depth: 2 out of 5\n",
      "Current Depth: 2 out of 5\n",
      "Current Depth: 2 out of 5\n",
      "Current Depth: 2 out of 5\n",
      "Current Depth: 3 out of 5\n",
      "Current Depth: 3 out of 5\n",
      "Current Depth: 3 out of 5\n",
      "Current Depth: 3 out of 5\n",
      "Current Depth: 3 out of 5\n",
      "Current Depth: 3 out of 5\n",
      "Current Depth: 3 out of 5\n"
     ]
    }
   ],
   "source": [
    "#chain = Chain(Status_model, Thought_model, Solution_model)\n",
    "#tree = BinTree(Status_model, Thought_model, Solution_model, Equivalence_model, Compare_model, max_depth=4)\n",
    "#tree(\"What is the solution to the equation x^2 - 4 = 0?\", T=1)\n",
    "tree = Tree(Status_model, Thought_model, Solution_model, None, Compare_model, max_depth=5)\n",
    "thoughts, best = tree(\"If I am not not not not not hungry, do I want to eat?\", T=1.5)\n",
    "#chain(\"If I am not not not not not hungry, do I want to eat?\", T=1, max_length=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['If I am not not not not not hungry, do I want to eat?',\n",
       "  'I need to simplify the negations to clarify whether appetite is present or absent.',\n",
       "  \"To understand the meaning of the multiple negations, I should keep track of the odd and even counts of the 'not' operator.\",\n",
       "  \"Since there are five 'not's in total (an odd count), this implies that the statement is equivalent to being hungry after simplifying the expressions.\"],\n",
       " \"If I am not not not not not hungry, do I want to eat? \\n-I need to simplify the negations to clarify whether appetite is present or absent. \\n-To understand the meaning of the multiple negations, I should keep track of the odd and even counts of the 'not' operator. \\n-Since there are five 'not's in total (an odd count), this implies that the statement is equivalent to being hungry after simplifying the expressions. \\nTherefore, I do want to eat because I am hungry after the simplification of the negations. \\nThe final answer is: Yes, I want to eat because I am hungry after resolving the negations.  \\n\\nSolution: Yes, I want to eat.\")"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thoughts, best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"If I am not not not not not hungry, do I want to eat? \\n-I need to simplify the negations to clarify whether appetite is present or absent. \\n-To understand the meaning of the multiple negations, I should keep track of the odd and even counts of the 'not' operator. \\n-Since there are five 'not's in total (an odd count), this implies that the statement is equivalent to being hungry after simplifying the expressions. \\nTherefore, I do want to eat because I am hungry after the simplification of the negations. \\nThe final answer is: Yes, I want to eat because I am hungry after resolving the negations.  \\n\\nSolution: Yes, I want to eat.\",\n",
       " \"If I am not not not not not hungry, do I want to eat?\\n-I need to simplify the negations to clarify whether appetite is present or absent.\\n-To simplify further, consider that each 'not' is essentially stating the opposite of the previous term, and I need to count these to reach a single conclusion about my hunger.\\n-I should count the total number of 'not' terms to determine if it resolves to being hungry or not.\\n-By counting the five instances of 'not', which are odd, this means the statement negates the original premise, revealing the final significance of the question about appetite.\\n\\nTherefore, the conclusion is that I am hungry, and yes, I want to eat.\"]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 1]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3][-1::-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
