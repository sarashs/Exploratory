{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c250241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Dict, Any, Literal, Callable, NamedTuple\n",
    "import json\n",
    "from pydantic import BaseModel, Field\n",
    "import random\n",
    "from langgraph.graph import StateGraph, END\n",
    "from openai import OpenAI\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c82e586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))\n",
    "def llm_call(system_prompt: str, prompt: str, OutputFormat: BaseModel, model: str = \"gpt-3.5-turbo-instruct-0914\"):\n",
    "    llm_out = client.responses.parse(\n",
    "        model=model,\n",
    "        input=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "               {\"role\": \"user\", \"content\": prompt}],\n",
    "        text_format=OutputFormat,\n",
    "    )\n",
    "    llm_out = llm_out.output_parsed\n",
    "    return llm_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46811cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MAX_ITERATIONS = 10\n",
    "TARGET_SCORE = 0.9\n",
    "\n",
    "# State definition\n",
    "class PromptEngineerState(TypedDict):\n",
    "    current_prompt: str\n",
    "    evaluation_dataset: List[Dict[str, Any]]\n",
    "    performance_metrics_string: str\n",
    "    performance_metrics: Dict[str, float]\n",
    "    failure_analysis: List[Dict[str, Any]]\n",
    "    improvement_actions: List[str]\n",
    "    iteration_count: int\n",
    "    best_prompt: str\n",
    "    best_score: float\n",
    "    search_history: List[Dict[str, Any]]\n",
    "    selected_action: str\n",
    "    epsilon_choice: str  # \"explore\" or \"exploit\"\n",
    "\n",
    "# Available improvement actions\n",
    "IMPROVEMENT_ACTIONS = [\n",
    "    \"Add/remove examples: This is pertaining to few-shot prompting. Try not to add examples directly from the feedback. Instead, create new examples that are similar in nature to the feedback.\",\n",
    "    \"Add/remove Chain of Thought reasoning: You can ask the model to think step-by-step, and output its reasoning. This may or may not improve the performance. You should consider removing it if it degrades the performance.\", \n",
    "    \"Add/remove specificity: A prompt or any aspect of a prompt can be more or less specific.\",\n",
    "    \"Add/remove context: Context can be added or removed to provide more or less information to the model.\",\n",
    "    \"Add/remove breaking the problem into subtasks: Consider breaking a complex problem into smaller, manageable subtasks, or consolidating subtasks into a single task if appropriate.\",\n",
    "    \"Add/remove role definitions: Clearly specify the role the model should assume when generating a response.\",\n",
    "    \"Add/remove constraints: Introduce constraints to guide the model's responses more effectively.\",\n",
    "    \"Add/remove asking for alternatives: Encourage the model to explore alternative solutions or perspectives.\",\n",
    "    \"Add/remove including negative examples: Provide examples of undesirable responses to help the model learn from mistakes.\",\n",
    "    \"Add/remove verification steps: Include steps for the model to verify its own answers.\",\n",
    "    \"Add/remove specifying thinking style: Instruct the model on the preferred style of reasoning or explanation.\",\n",
    "    \"Add/remove including edge cases: Encourage the model to consider edge cases in its responses.\",\n",
    "    \"Add/remove quality criteria: Specify the criteria that the model's responses should meet.\",\n",
    "    \"Add/remove requesting explanations: Ask the model to explain its reasoning or thought process.\",\n",
    "    \"Other: This is a catch-all for any other improvement action that may not fit the above categories.\",\n",
    "]\n",
    "\n",
    "##############################################\n",
    "# Epsilon-greedy strategy for prompt selection\n",
    "##############################################\n",
    "\n",
    "class PromptTemplateData(NamedTuple):\n",
    "    prompt: str\n",
    "    system_prompt: str\n",
    "    prompt_format_function: Callable[[str], str] = lambda x: x\n",
    "    output_format: BaseModel = None\n",
    "\n",
    "class PromptOptimizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        #failure_analysis: PromptTemplateData,\n",
    "        action_selection: PromptTemplateData,\n",
    "        action_application: PromptTemplateData,\n",
    "        initial_prompt: PromptTemplateData,\n",
    "        evaluation_method: Callable[[PromptTemplateData, List[Any]], Dict[str, float]],\n",
    "        training_dataset: List[Any],\n",
    "        action_list: List[str] = IMPROVEMENT_ACTIONS,\n",
    "        train_test_ratio: float = 0.5,\n",
    "        epsilon: float = 0.3,  # exploration rate\n",
    "        epsilon_decay: float = 0.95,  # decay rate for epsilon\n",
    "        min_epsilon: float = 0.1,  # minimum exploration rate\n",
    "    ):\n",
    "        #self.failure_analysis = failure_analysis\n",
    "        self.action_selection = action_selection\n",
    "        self.action_application = action_application\n",
    "        self.action_list = action_list\n",
    "        self.initial_prompt = initial_prompt\n",
    "        self.evaluation_method = evaluation_method\n",
    "        self.training_dataset, self.evaluation_dataset = train_test_split(\n",
    "            training_dataset, test_size=1 - train_test_ratio, random_state=42\n",
    "        )\n",
    "\n",
    "        # Epsilon-greedy parameters\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.min_epsilon = min_epsilon\n",
    "\n",
    "        # Build the workflow\n",
    "        self.workflow = StateGraph(PromptEngineerState)\n",
    "        self.workflow.add_node(\"evaluate\", self.evaluate_prompt_node)\n",
    "        #self.workflow.add_node(\"analyze_failures\", self.analyze_failures_node)\n",
    "        self.workflow.add_node(\"epsilon_greedy_choice\", self.epsilon_greedy_choice_node)\n",
    "        self.workflow.add_node(\"select_action\", self.select_action_node)\n",
    "        self.workflow.add_node(\"apply_action\", self.apply_action_node)\n",
    "\n",
    "        #self.workflow.add_edge(\"evaluate\", \"analyze_failures\")\n",
    "        self.workflow.add_edge(\"evaluate\", \"epsilon_greedy_choice\")\n",
    "        self.workflow.add_edge(\"epsilon_greedy_choice\", \"select_action\")\n",
    "        self.workflow.add_edge(\"select_action\", \"apply_action\")\n",
    "        self.workflow.add_conditional_edges(\"apply_action\", self.should_continue)\n",
    "        self.workflow.set_entry_point(\"evaluate\")\n",
    "        self.app = self.workflow.compile()\n",
    "\n",
    "    def evaluate_prompt_node(self, state: PromptEngineerState) -> PromptEngineerState:\n",
    "        print(f\"🔍 Evaluating prompt (iteration {state['iteration_count']})\")\n",
    "        \n",
    "        # Generate metrics\n",
    "        metrics = self.evaluation_method(state[\"current_prompt\"], self.training_dataset)\n",
    "        validation_metrics = self.evaluation_method(state[\"current_prompt\"], self.evaluation_dataset)\n",
    "        accuracy = metrics.get(\"accuracy\", 0)\n",
    "        recall = metrics.get(\"recall\", 0)\n",
    "        precision = metrics.get(\"precision\", 0)\n",
    "        false_positive_rate = metrics.get(\"false_positive_rate\", 0)\n",
    "        # Calculate F1 score\n",
    "        if precision + recall > 0:\n",
    "            f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        else:\n",
    "            f1_score = 0\n",
    "        # calculate f1 score for validation dataset\n",
    "        if validation_metrics.get(\"precision\", 0) + validation_metrics.get(\"recall\", 0) > 0:\n",
    "            validation_f1_score = 2 * (validation_metrics.get(\"precision\", 0) * validation_metrics.get(\"recall\", 0)) / (validation_metrics.get(\"precision\", 0) + validation_metrics.get(\"recall\", 0))\n",
    "        else:\n",
    "            validation_f1_score = 0\n",
    "        # Extract failure cases\n",
    "        if \"failure_cases\" in metrics:  # Ensure failure_cases is in metrics\n",
    "            failure_cases = metrics[\"failure_cases\"]\n",
    "        else:\n",
    "            failure_cases = []\n",
    "        metrics = {\n",
    "            \"validation_accuracy\": validation_metrics.get(\"accuracy\", 0),\n",
    "            \"validation_recall\": validation_metrics.get(\"recall\", 0),\n",
    "            \"validation_precision\": validation_metrics.get(\"precision\", 0),\n",
    "            \"validation_f1_score\": validation_f1_score,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"recall\": recall,\n",
    "            \"precision\": precision,\n",
    "            \"f1_score\": f1_score,\n",
    "            \"false_positive_rate\": false_positive_rate,\n",
    "            \"failure_cases\": \"\\n\".join(failure_cases) if failure_cases else \"None\" # convert list to string to feed to the llm\n",
    "        }\n",
    "        \n",
    "        # Track best prompt globally\n",
    "        new_best_prompt = state[\"best_prompt\"]\n",
    "        new_best_score = state[\"best_score\"]\n",
    "        \n",
    "        if f1_score > state[\"best_score\"]:\n",
    "            new_best_prompt = state[\"current_prompt\"]\n",
    "            new_best_score = f1_score\n",
    "            print(f\"🎉 New best score: {f1_score:.3f}\")\n",
    "\n",
    "        #performance_metrics_string = ''\n",
    "        #for item in metrics:\n",
    "        #    performance_metrics_string += f\"{item}:\\n {metrics[item]}\\n\"\n",
    "        \n",
    "        performance_metrics_string = ''\n",
    "        for item in metrics:\n",
    "            performance_metrics_string += f\"{item}:\\n {metrics[item]}\\n\"\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"performance_metrics_string\": performance_metrics_string,\n",
    "            \"performance_metrics\": metrics,\n",
    "            \"best_prompt\": new_best_prompt,\n",
    "            \"best_score\": new_best_score\n",
    "        }\n",
    "\n",
    "    def epsilon_greedy_choice_node(self, state: PromptEngineerState) -> PromptEngineerState:\n",
    "        \"\"\"Epsilon-greedy choice: continue current prompt with prob epsilon, or use best prompt with prob 1-epsilon\"\"\"\n",
    "        current_epsilon = max(self.min_epsilon, self.epsilon * (self.epsilon_decay ** state[\"iteration_count\"])) # Decay epsilon via a power function\n",
    "        \n",
    "        if random.random() < current_epsilon:\n",
    "            # Explore: continue with current prompt (go to action selection)\n",
    "            print(f\"🔍 Exploring - continuing with current prompt (ε={current_epsilon:.3f})\")\n",
    "            choice = \"explore\"\n",
    "        else:\n",
    "            # Exploit: use best known prompt (skip to next iteration)\n",
    "            print(f\"💰 Exploiting - using best known prompt (ε={current_epsilon:.3f})\")\n",
    "            choice = \"exploit\"\n",
    "            # Set current prompt to best prompt\n",
    "            state = {\n",
    "                **state,\n",
    "                \"current_prompt\": state[\"best_prompt\"] if state[\"best_prompt\"] else state[\"current_prompt\"]\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"epsilon_choice\": choice\n",
    "        }\n",
    "\n",
    "    def select_action_node(self, state: PromptEngineerState) -> PromptEngineerState:\n",
    "        print(\"🤖 Selecting improvement action\")\n",
    "        \n",
    "        metrics = state[\"performance_metrics\"]\n",
    "        \n",
    "        # LLM based action selection\n",
    "        random.shuffle(self.action_list) # We shuffle to debias the llm's potential location bias\n",
    "        llm_action_output = llm_call(\n",
    "            system_prompt=self.action_selection.system_prompt,\n",
    "            prompt= self.action_selection.prompt_format_function(\n",
    "            prompt = self.action_selection.prompt,\n",
    "            current_prompt=state[\"current_prompt\"],\n",
    "            performance_metrics=json.dumps({k: v for k, v in metrics.items() if not k.startswith(\"validation_\")}, indent=2),\n",
    "            improvement_actions=\", \".join(self.action_list),\n",
    "            ),\n",
    "            OutputFormat=self.action_selection.output_format,\n",
    "        )\n",
    "\n",
    "        selected_action = llm_action_output.get(\"action\", None)\n",
    "        assert selected_action is not None, \"LLM did not return a valid action. Please check the action selection prompt and the LLM response format.\"\n",
    "        \n",
    "        print(f\"🎯 Selected action: {selected_action}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"selected_action\": selected_action\n",
    "        }\n",
    "\n",
    "    def apply_action_node(self, state: PromptEngineerState) -> PromptEngineerState:\n",
    "        print(f\"⚡ Applying action: {state['selected_action']}\")\n",
    "        action = state[\"selected_action\"]\n",
    "        current_prompt = state[\"current_prompt\"]\n",
    "        \n",
    "        # Apply the selected action to modify the prompt\n",
    "        llm_new_prompt_output = llm_call(\n",
    "            system_prompt=self.action_application.system_prompt,\n",
    "            prompt=self.action_application.prompt_format_function(\n",
    "                prompt=self.action_application.prompt,\n",
    "                selected_action=action,\n",
    "                current_prompt=current_prompt,\n",
    "                performance_metrics=json.dumps({k: v for k, v in metrics.items() if not k.startswith(\"validation_\")}, indent=2),\n",
    "            ),\n",
    "            OutputFormat=self.action_application.output_format,\n",
    "        )\n",
    "\n",
    "        new_prompt = llm_new_prompt_output.get(\"new_prompt\", current_prompt)\n",
    "        assert new_prompt is not None, \"LLM did not return a valid new prompt. Please check the action application prompt and the LLM response format.\"\n",
    "\n",
    "        new_history = state[\"search_history\"] + [{\n",
    "            \"iteration\": state[\"iteration_count\"],\n",
    "            \"action\": action,\n",
    "            \"prompt\": new_prompt,\n",
    "            \"metrics\": state[\"performance_metrics\"], \n",
    "        }]\n",
    "\n",
    "        print(f\"iteration: {state['iteration_count']} | action: {action} | training f1_score: {state['performance_metrics']['f1_score']:.3f} | validation f1_score: {state['performance_metrics']['validation_f1_score']:.3f}\")\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"current_prompt\": new_prompt,\n",
    "            \"iteration_count\": state[\"iteration_count\"] + 1,\n",
    "            \"search_history\": new_history\n",
    "        }\n",
    "\n",
    "    def should_continue(self, state: PromptEngineerState) -> Literal[\"evaluate\", \"__end__\"]:\n",
    "        if state[\"iteration_count\"] >= MAX_ITERATIONS:\n",
    "            print(f\"🛑 Max iterations ({MAX_ITERATIONS}) reached\")\n",
    "            return \"__end__\"\n",
    "        if state[\"performance_metrics\"][\"f1_score\"] >= TARGET_SCORE:\n",
    "            print(f\"🎯 Target score ({TARGET_SCORE}) achieved!\")\n",
    "            return \"__end__\"\n",
    "        return \"evaluate\"\n",
    "\n",
    "    def visualize(self):\n",
    "        try:\n",
    "            from IPython.display import Image, display\n",
    "            display(Image(self.app.get_graph().draw_mermaid_png()))\n",
    "        except ImportError:\n",
    "            print(\"To visualize the graph, install: pip install grandalf\")\n",
    "            print(\"Or use: app.get_graph().print_ascii()\")\n",
    "            print(\"\\nWorkflow Graph (ASCII):\")\n",
    "            self.app.get_graph().print_ascii()\n",
    "    \n",
    "    def run(self) -> PromptEngineerState:\n",
    "        initial_state: PromptEngineerState = {\n",
    "            \"current_prompt\": self.initial_prompt,\n",
    "            \"evaluation_dataset\": self.evaluation_dataset,\n",
    "            \"performance_metrics_string\": \"\",\n",
    "            \"performance_metrics\": {},\n",
    "            \"failure_analysis\": [],\n",
    "            \"improvement_actions\": [],\n",
    "            \"iteration_count\": 0,\n",
    "            \"best_prompt\": self.initial_prompt,\n",
    "            \"best_score\": 0.0,\n",
    "            \"search_history\": [],\n",
    "            \"selected_action\": \"\",\n",
    "            \"epsilon_choice\": \"\"\n",
    "        }\n",
    "        final_state = self.app.invoke(initial_state)\n",
    "        return final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86ea3169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import notebook\n",
    "training_dataset = pd.read_csv(\"Train.csv\").sample(200, random_state=42)\n",
    "\n",
    "def evaluation_method(prompt: PromptTemplateData, dataset: pd.DataFrame) -> Dict[str, float]:\n",
    "    # evaluation method for demonstration\n",
    "    prediction = []\n",
    "    for index, row in notebook.tqdm(dataset.iterrows(), total=len(dataset)):\n",
    "        system_prompt = prompt.system_prompt\n",
    "        formatted_prompt = prompt.prompt_format_function(prompt.prompt, row['text'])\n",
    "        OutputFormat = prompt.output_format\n",
    "        llm_response = llm_call(system_prompt=system_prompt, prompt=formatted_prompt, OutputFormat=OutputFormat, model=\"gpt-4o\")\n",
    "        prediction.append(1 if llm_response.sentiment else 0)\n",
    "    actual = dataset['label'].to_list()\n",
    "    precision = sum(p == a == 1 for p, a in zip(prediction, actual)) / sum(p == 1 for p in prediction) if sum(p == 1 for p in prediction) > 0 else 0\n",
    "    recall = sum(p == a == 1 for p, a in zip(prediction, actual)) / sum(a == 1 for a in actual) if sum(a == 1 for a in actual) > 0 else 0\n",
    "    return {\n",
    "        \"accuracy\": sum(p == a for p, a in zip(prediction, actual)) / len(actual),\n",
    "        \"recall\": recall,\n",
    "        \"precision\": precision,\n",
    "        \"f1_score\": 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0,\n",
    "        \"false_positive_rate\": sum(p == 1 and a == 0 for p, a in zip(prediction, actual)) / sum(a == 0 for a in actual) if sum(a == 0 for a in actual) > 0 else 0,\n",
    "        \"failure_cases\": [row + f\" predicted: {prediction[i]}\" + f\" actual: {row['label']}\" for i, (index, row) in enumerate(dataset.iterrows()) if row['label'] != prediction[i]]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78f2a008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the output formats for LLM nodes\n",
    "class ActionOutputFormat(BaseModel):\n",
    "    \"\"\"Output format for the action selection step.\"\"\"\n",
    "    cot: str = Field(..., description=\"Chain of thought reasoning for the selected action.\")\n",
    "    action: str = Field(..., description=\"The selected action to apply to the current prompt.\")\n",
    "\n",
    "class ActionApplicationOutputFormat(BaseModel):\n",
    "    \"\"\"Output format for the action application step.\"\"\"\n",
    "    cot: str = Field(..., description=\"Chain of thought reasoning for the action application.\")\n",
    "    new_prompt: str = Field(..., description=\"The new prompt after applying the selected action.\")\n",
    "\n",
    "class InitialPromptOutputFormat(BaseModel):\n",
    "    \"\"\"Output format for the initial prompt.\"\"\"\n",
    "    sentiment: bool = Field(..., description=\"sentiment analysis of the text either positive/True or negarive/False\")\n",
    "    other: str = Field(..., description=\"Everything else requested by the prompt in string format.\")\n",
    "\n",
    "initial_prompt=PromptTemplateData(\n",
    "    prompt=\"For the following given text return true if the sentiment is positive, otherwise return false. \\nText: {text}\",\n",
    "    system_prompt=\"You are an expert in extracting the comment sentiment from the given text.\",\n",
    "    output_format=InitialPromptOutputFormat,\n",
    "    prompt_format_function=lambda x, y: x.format(text=y)\n",
    ")\n",
    "\n",
    "# Initialize the PromptOptimizer with the initial prompt and evaluation method\n",
    "po = PromptOptimizer(\n",
    "    evaluation_method=evaluation_method,     # evaluation method for demonstration\n",
    "    training_dataset=training_dataset,\n",
    "    action_selection=PromptTemplateData(\n",
    "        prompt=\"Select an improvement action based on failure analysis: \\nCurrent Prompt: {current_prompt}\\nPerformance Metrics: {performance_metrics}\\nImprovement Actions: {improvement_actions}\",\n",
    "        system_prompt=\"\"\"You are an expert prompt engineer. Your task is to optimize prompts for a given task.\n",
    "        You will be provided with a current prompt, a dataset for evaluation, and a set of improvement actions.\n",
    "        Your goal is to iteratively improve the prompt based on performance metrics and failure analysis.\n",
    "        You will select an action to apply to the current prompt, and then apply that action to generate a new prompt.\n",
    "        The process will continue until the performance metrics meet the target score or the maximum number of iterations is reached.\n",
    "        \"\"\",\n",
    "        output_format=ActionOutputFormat,\n",
    "        prompt_format_function=lambda x, y: x.format(**y)\n",
    "    ),\n",
    "    action_application=PromptTemplateData(\n",
    "        prompt=\"Apply the selected action to the current prompt:\\n {selected_action} \\nCurrent Prompt: {current_prompt}\\nPerformance Metrics: {performance_metrics}\",\n",
    "        system_prompt=\"\"\"Your task is to improve a prompt based on the selection action and performance metrics.\n",
    "        You should provide the new prompt that results from applying the action to the current prompt. Make sure the new prompt is clear, concise, and effectively incorporates the selected improvement action.\n",
    "        Do not change any other aspect of the prompt except for the selected action.\"\"\",\n",
    "        prompt_format_function=lambda x, y: x.format(**y)\n",
    "    ),\n",
    "    initial_prompt=PromptTemplateData(\n",
    "        prompt=\"For the following given text return true if the sentiment is positive, otherwise return false. \\nText: {text}\",\n",
    "        system_prompt=\"You are an expert in extracting the comment sentiment from the given text.\",\n",
    "        output_format=InitialPromptOutputFormat,\n",
    "        prompt_format_function=lambda x, y: x.format(text=y)\n",
    "    ),\n",
    "    action_list=IMPROVEMENT_ACTIONS,\n",
    "    train_test_ratio=0.8,\n",
    ")\n",
    "\n",
    "po.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6bf02ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Evaluating prompt (iteration 0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a0cff69e8c4699ac7d307d066d14b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m final_state \u001b[38;5;241m=\u001b[39m \u001b[43mpo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 278\u001b[0m, in \u001b[0;36mPromptOptimizer.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptEngineerState:\n\u001b[1;32m    264\u001b[0m     initial_state: PromptEngineerState \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_prompt,\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepsilon_choice\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    277\u001b[0m     }\n\u001b[0;32m--> 278\u001b[0m     final_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m final_state\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2844\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[0m\n\u001b[1;32m   2841\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2842\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2844\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   2845\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2846\u001b[0m     config,\n\u001b[1;32m   2847\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2848\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2849\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[1;32m   2850\u001b[0m     print_mode\u001b[38;5;241m=\u001b[39mprint_mode,\n\u001b[1;32m   2851\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   2852\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   2853\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   2854\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2855\u001b[0m ):\n\u001b[1;32m   2856\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2857\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2534\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2532\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[1;32m   2533\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 2534\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   2535\u001b[0m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[1;32m   2536\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   2537\u001b[0m     get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   2538\u001b[0m     schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[1;32m   2539\u001b[0m ):\n\u001b[1;32m   2540\u001b[0m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   2541\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _output(\n\u001b[1;32m   2542\u001b[0m         stream_mode, print_mode, subgraphs, stream\u001b[38;5;241m.\u001b[39mget, queue\u001b[38;5;241m.\u001b[39mEmpty\n\u001b[1;32m   2543\u001b[0m     )\n\u001b[1;32m   2544\u001b[0m loop\u001b[38;5;241m.\u001b[39mafter_tick()\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/langgraph/pregel/runner.py:162\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[1;32m    160\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 162\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/langgraph/pregel/retry.py:42\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     40\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     44\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/langgraph/utils/runnable.py:623\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m--> 623\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/langgraph/utils/runnable.py:377\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 377\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[18], line 99\u001b[0m, in \u001b[0;36mPromptOptimizer.evaluate_prompt_node\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🔍 Evaluating prompt (iteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miteration_count\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Generate metrics\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcurrent_prompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m validation_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_method(state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent_prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_dataset)\n\u001b[1;32m    101\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[23], line 11\u001b[0m, in \u001b[0;36mevaluation_method\u001b[0;34m(prompt, dataset)\u001b[0m\n\u001b[1;32m      9\u001b[0m     formatted_prompt \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mprompt_format_function(prompt\u001b[38;5;241m.\u001b[39mprompt, row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m     OutputFormat \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39moutput_format\n\u001b[0;32m---> 11\u001b[0m     llm_response \u001b[38;5;241m=\u001b[39m \u001b[43mllm_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatted_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOutputFormat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOutputFormat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     prediction\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m llm_response\u001b[38;5;241m.\u001b[39msentiment \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     13\u001b[0m actual \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/tenacity/__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/tenacity/__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/tenacity/__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/tenacity/__init__.py:398\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[0;32m--> 398\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/tenacity/__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m, in \u001b[0;36mllm_call\u001b[0;34m(system_prompt, prompt, OutputFormat, model)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;129m@retry\u001b[39m(stop\u001b[38;5;241m=\u001b[39mstop_after_attempt(\u001b[38;5;241m3\u001b[39m), wait\u001b[38;5;241m=\u001b[39mwait_exponential(multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mllm_call\u001b[39m(system_prompt: \u001b[38;5;28mstr\u001b[39m, prompt: \u001b[38;5;28mstr\u001b[39m, OutputFormat: BaseModel, model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-3.5-turbo-instruct-0914\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     llm_out \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m               \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOutputFormat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     llm_out \u001b[38;5;241m=\u001b[39m llm_out\u001b[38;5;241m.\u001b[39moutput_parsed\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m llm_out\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/openai/resources/responses/responses.py:995\u001b[0m, in \u001b[0;36mResponses.parse\u001b[0;34m(self, text_format, background, include, input, instructions, max_output_tokens, max_tool_calls, metadata, model, parallel_tool_calls, previous_response_id, prompt, reasoning, service_tier, store, stream, temperature, text, tool_choice, tools, top_logprobs, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparser\u001b[39m(raw_response: Response) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ParsedResponse[TextFormatT]:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parse_response(\n\u001b[1;32m    990\u001b[0m         input_tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[1;32m    991\u001b[0m         text_format\u001b[38;5;241m=\u001b[39mtext_format,\n\u001b[1;32m    992\u001b[0m         response\u001b[38;5;241m=\u001b[39mraw_response,\n\u001b[1;32m    993\u001b[0m     )\n\u001b[0;32m--> 995\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/responses\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackground\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minclude\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minstructions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_output_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprevious_response_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtruncation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResponseCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `Response` instance into a `ParsedResponse`\u001b[39;49;00m\n\u001b[1;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[1;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedResponse\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTextFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mResponse\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/openai/_base_client.py:1256\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1244\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1251\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1252\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1253\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1254\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1255\u001b[0m     )\n\u001b[0;32m-> 1256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/openai/_base_client.py:979\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    977\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 979\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    985\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/env-310/lib/python3.10/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1292\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1290\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1291\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1165\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "final_state = po.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
